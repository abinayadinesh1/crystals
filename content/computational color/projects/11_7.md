dichromat designers
take dichromat drawing and reconstruct r channel from it: dichromats can visualize

looking for benchmark to evaluate how good their tools are and do they support people's creativity?
creativity support index to measure how well each of their tools are working?



color fields, referece image
colorful colorization
	go from monochromatic to trichromatic
		if the predict a and b values independently, theyd get very grey images. 

what is the learning curve for developing an intuition for these different representations of color?

2 qs:
1) for the color fields paper, 
	is the idea for the color fields paper to have a rgb image, show the 
	have an rgb image, apply the dichromat filter over it, and show the gradient fields from the colors in the 3d image to the 2d image so the dichromat knows the original color (in 3d space) of what they see in 2d space
2) for the color to patterning (red being dense dots and yellow being curvy dots)
	when looking at the patterning on the normal image, it seems really hard to tell apart the different patterns when the colors in the image change fast. it might help to just upscale the image (like a 3x aspect ratio) and then apply the patterning so there is enough space to see patterns between colors emerge. 


light leakage using coretsumo model
coretsumo - using aoslo (or microdosing, which can miss the cone cell it wants to target or have light leakage effects) to see if we can boost color dimensionality
	how does light leakage impact the boosting of color dimensionality
replicate failure modes using compneuro model 
	protanopic - easier to train. 
	electroretinogram


when they blur the retina (like in light leakage), the image also gets very blurry and slightly more yellow (?)



nature vision
uv intensity being dependent on rgb and reflectivity of the surface
white flower though to reflect a lot of uv, but actually absorbed lots of it
dark, where more ov is being ABSORBED. pollinators would go to the dark regions: rich with pollen. 

ultraviolet patterns of flowers relealed in polymer replica
a lot of yellow looks very different to bees and birds, high activation in uv spectrum. 


recording animal view videos of the natural world - map the rgb images to what a bee would visualize. 
	beam splitter to map photons into two different sensors
	map intensity and transmission functions of human vision to birds and bees
	**how do gmo plants to increase the reflectance of things that birds and bees will pollinate**
look into uv photography and ir photography for reolorization
blending uv image with rgb image
building simple gui for mixing colors
cv auto match: define two key points of images and match them together. 
	cross spectral alignment of images
		cant do it, so predict nir from rgb and try to match. 
	weather alignment of images 
how to capture perfeclty aligned images:
	inmplement autoexposure for uv
	time the taking of the images based on shutter speed so both image takings end at exactly the same time. 
taking it as raw data
scientifically meaningful 


https://tech.facebook.com/artificial-intelligence/2020/5/deepfovea-ar-vr-rendering-inspired-by-human-vision/
go through literature to find spectral responsivity curves of a hummingbird
whiteboard on representing 4d color vision for hummingbirds
clean up code 
	store image as png with fourth channel being a 
	then use simple dataset, instead of tetradataset
corteva


floral coloration, its colorimetric analysis and significance in anthecology
stodder group studying hummingbirds
multispectral, uv and led signaling lights

fruit flies are tetrachromatic (uv + rgb) -> fruit fly vision 
	universal color generator for a fruit fly
	how do you make a display for a fruit fly
# color in practice - a sampling 

color is complicated! perceptual thing
	sensation based on spd of the world
color appearance, adaptation reproduction - mark fairchild's world
	munsell color lab
	book on color appearance models
[CAM16](https://observablehq.com/@jrus/cam16) 
CIELAB gets us vv far (beyond rgb and lms)

chromatic adaptation
	color is very contextual
	lotto cube
	![[Pasted image 20231107145310.png]]
	unrelated color - perceived by itself, isolated from any contrasting color areas or any visible physical context
	related color - perceived in the same visual field as one or more contrasting color areas
		brown and grey are only related colors

CIELAB
	how do u go from rgb to appearance of color
		chromatic adaptation component to the model (whitebalance - interpret all the colors relative to what is white or neutral in the scene)
	predicts color appearance
		formulas for hue (what color on the rainbow), chroma (saturation), lightness (distance from white/black)
	perceptual unifromity
		non linear warping from 3d to perceptual understanding
	can i map from srgb to cielab non destructively? yes
	just page of functions to go from XYZ to LAB
	XYZ canonical 3d linear color space
		default standard color space for all colors u can see in the human gamut
when u apply a filter to an image, the new Xn Yn and Zn are the relative whites
why XYZ is great!
	color adaptation
	non linearity
	easy to implement, invertible

wrong von kries model
	notion of chromatic adaptation related to perceptually, neurally, what is going on. 
	nerves that correspond to L, M, and S channels are the ones doing the normalization

chromaticity - leave out brightness.lightness, just get hue and saturated
	chromaticity diagram from XYZ, inside the elipses, looks like the same color
	can do proximity perceptual judgements
	![[Pasted image 20231107151145.png]]
	mcaddams ellipse
	jand , just notieable difference, inside a ellipse the ability to tell diff 

CIELAB gives recommended color difference metric
	delta E for distance between colors
	depth estimation - not clear that LAB would be better
		when i have 3 color channels of info, which estimator converts from channels to depth
	trying to colorize images from black and white:
		choice between RGB loss or CIELAB loss, CIELAB loss is better
every balance does automatic white balance through wrong von kries adaptation


ciecat02 - from XYZ space to LAB space, then does normalization in LMS and converts it back
	maxwell, color matching experiments
	what are the spectral response functions of the photoreceptors? 
		took 100 years to isolate down to photopigments in cells and measure with white light source and monochromater what the sensitivities were
	when they defined XYZ, didnt have LMS. 
	stockman and sharpe
	wikepedia page of LMS
display is more color accurate to the viewing environment you are in 
	to implement this, we need a color appearance model
colorspaces chromaticity diagrams - michael s brown 

maureen stone
data science
	LMS euclidian 3 space
	wavelength by wavelength, see what the LMS values are, think of that as a point in 3 space, 
		space filling curve
		can never stimulate just one of these axis
		get spectral locus
what is the gamut of colors we can see?
	any spd in the world has a certain power at a specific wavelength. final response from L, M, and S is a point in space. 
<mark style="background: #ADCCFFA6;">		have spd of smth i see in the world, integrate over all wavelengths, get the power at each wavelength and multiply it by our LMS intensity. </mark>
	convex hull of this space filling curve projected out into the origin of LMS euclidian spacec

maxwellian triangle
XYZ is an arbitrary, historical, useful basis
	CIE xy chromaticity diagram


CIE 1931 RGB, XYZ
	CIE RGB color matching experiment

computer graphics, principles and practice, plates ii.1, ii.2



# random 

isabelle and susan and jacob
https://people.eecs.berkeley.edu/~bjoern/
berkeley hair studio 

**need to do comp neuro progress**, train the model on our initial images
literature on hummingbirds - how were people analyzing hummingbird vision
berkeley hummingbird uv vision and coloration helps them find mates

what we're doing, where we are at
with 8 minutes, what are we gonna tell someone
phase 2 demos, final phase pitch
	what have we done so far
	where do we want to go 


final presentations, report and video due


todo
start eps homework 
read agroecology readings 
	willow
	<s>luke privatization </s>
clean up compneuro model 
	look into building this 3d matrix
reach out to corteva
	make full project page
reach out to person james said
reach out to google x person that judged ai in motion hackathon (https://www.ashleyqswartz.com/)
respond to hongxu and david 
reach out to guy who has the ml curriculum i wanna do 